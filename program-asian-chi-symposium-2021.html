<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE-edge">
        <meta name="title" content="Asian CHI 2021 Symposium">
        <meta name="description" content="Asian CHI 2021 Symposium">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Asian CHI 2021 Symposium</title>
        <link rel="stylesheet" type="text/css" href="style2.css">
        <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Mulish:wght@400;700&display=swap" rel="stylesheet">
    </head>
    <body>
        <div id="loader-wrapper">
            <div class="lds-ring"><div></div><div></div><div></div><div></div></div>
        </div>
        <button id="goToTop" title="Go to top">
            <span>
                <img width="24px" height="24px" class="up-arrow" alt="up-arrow" src="icons/up-arrow.svg">
            </span>
        </button>
        <div class="accessibility-icons">
            <div class="text-size">

            </div>
            <div class="contrast">

            </div>
        </div>
        <header>
            <nav>
                <div class="logo nav-item">
                    <a href="./index.html">ASIAN CHI SYMPOSIUM 2021</a>
                </div>
                <ul class="nav-links nav-menu">
                    <!-- <li class="nav-item">
                        <a href="./index.html">Asian CHI Symposium</a>
                    </li> -->
                    <li class="nav-item">
                        <a href="./index.html">Home</a>
                    </li>
                     <li class="nav-item">
                        <a href="./program-asian-chi-symposium-2021.html">Program</a>
                    </li>
                    <li class="dropdown">
                        <button class="dropbtn">Call for Papers
                            <span>
                                <img height="8px" width="10px" class="caret-down" alt="caret-down" src="icons/caret-down.svg">
                            </span>
                        </button>
                        <ul class="dropdown-content dropdown_menu--animated">
                            <a href="./call-for-paper-En-asian-chi-symposium-2021.html">English</a>
                            <a href="./call-for-paper-Ch-asian-chi-symposium-2021.html">Chinese</a>
                            <a href="./call-for-paper-Malay-asian-chi-symposium-2021.html">Malay</a>
                            <a href="./call-for-paper-Jp-asian-chi-symposium-2021.html">Japanese</a>
                            <a href="./call-for-paper-Kr-asian-chi-symposium-2021.html">Korean</a>
                            <a href="./call-for-paper-Thai-asian-chi-symposium-2021.html">Thai</a>
                            <a href="./call-for-paper-Id-asian-chi-symposium-2021.html">Bahasa Indonesia</a>
                        </ul>
                        <!-- <a href="./cfpEn.html">Call For Paper (EN)</a> -->
                    </li>
                    <li class="cfp-languages nav-item">
                        <p>Call for Papers</p>
                        <ul class="sub-nav-group dropdown-menu dropdown_menu--animated ">
                            <li><a href="./call-for-paper-En-asian-chi-symposium-2021.html">English</a></li>
                            <li><a href="./call-for-paper-Ch-asian-chi-symposium-2021.html">Chinese</a></li>
                            <li><a href="./call-for-paper-Malay-asian-chi-symposium-2021.html">Malay</a></li>
                            <li><a href="./call-for-paper-Jp-asian-chi-symposium-2021.html">Japanese</a></li>
                            <li><a href="./call-for-paper-Kr-asian-chi-symposium-2021.html">Korean</a></li>
                            <li><a href="./call-for-paper-Thai-asian-chi-symposium-2021.html">Thai</a></li>
                            <li><a href="./call-for-paper-Id-asian-chi-symposium-2021.html">Bahasa Indonesia</a></li>
                        </ul>
                    </li>
                    <li class="nav-item">
                        <a href="./attending-asian-chi-symposium-2021.html">Registration</a>
                    </li>
                    <li class="nav-item">
                        <a href="./organizers-asian-chi-symposium-2021.html">Organizers</a>
                    </li>
                    <li class="nav-item">
                        <a href="./pastEvents-asian-chi-symposium-2021.html">Past Events</a>
                    </li>
                </ul>
                <div class="burger-menu">
                    <div class="line1"></div>
                    <div class="line2"></div>
                    <div class="line3"></div>
                </div>
            </nav>
            <div class="container header-picture">
                <!-- <div class="header__bg"></div> -->
                <div class="multiply-picture"></div>
                <div class="text-title">
                    <ul>
                        <li><h1>Program</h1></li>
                    </ul>
                    <!-- <img class="chi-logo" src="images/chi-logo-clear.png"> -->
                </div>
                <div class="multiply-picture">
                </div>
            </div>
            <!-- <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 150 100" preserveAspectRatio="none">
                <circle fill="white" cx="0" cy="100" r="100" />
                <circle fill="white" cx="200" cy="100" r="100" />
            </svg> -->
        </header>
        <script src="app.js"></script>

        <main class="mainpage-content">
            <div></div>
            <div id="programs" class="programs">
                <div class="program-content">
                    <ul class="table-of-content">
                        <li> <a href="#day-1" style="text-decoration: none; color: #0667DB;">Day 1</a> </li>
                        <li><a href="#day-2" style="text-decoration: none; color: #0667DB;" style="border-left: 0px; padding-left: 0">Day 2</a></li>
                        <li><a href="#keynote-speakers" style="text-decoration: none; color: #0667DB;" style="border-left: 0px; padding-left: 0">Keynote Speakers</a></li>
                    </ul>
                    <h5>SIGCHI Asian CHI Symposium programs link can be found <a href="https://programs.sigchi.org/chi/2021/program/content/57150">here</a></h5>
                </div>
                <div id="programs-time" class="programs-time">
                    <h2 id="day-1">Day 1 - May 7, 2021</h2>
                    <p>The programs will be done according to Japan time <a class="timezone-link" href="https://24timezones.com/time-zone/gmt+9#gref">(GMT + 09).</a></p>
                    <table class="programs-time">
                        <tbody>
                            <tr>
                                <th style="width:30%">Time (JST)</th>
                                <th style="width:70%">Program</th>
                            </tr>
                            <tr>
                                <td>
                                    <p>13:00 ~ 13:10</p>
                                </td>
                                <td class="important-date">
                                    <div>
                                        <p class="prog-title">Opening</p>
                                        <p class="text-muted">Speaker: Josh Tedjasaputra, General Chair</p>
                                    </div>
                                    </td>
                            </tr>
                            <tr>
                                <td>
                                    <p>13:10 ~ 13:45</p>
                                </td>
                                <td class="important-date">
                                    <div>
                                        <p class="prog-title">Keynote 1 - Gierad Laput, Apple | <a href="#gierad_laput">Bio & Abstract</a></p>
                                        <p class="text-muted">Session Chair: Briane Samson</p>
                                    </div>
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <p>13:45 ~ 13:50</p>
                                </td>
                                <td class="important-date">Break</td>
                            </tr>
                            <tr>
                                <td>
                                    <p>13:50 ~ 14:35</p>
                                </td>
                                <!-- <td class="important-date">Paper session 1 (7 pax)</td> -->
                                <td class="important-date">
                                    <div>
                                        <p class="prog-title">Paper Session 1 (7 papers)</a></p>
                                        <p class="text-muted">Session Chair: Pranjal Jain</p>
                                    </div>
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <p>15:40 ~ 15:45</p>
                                </td>
                                <td class="important-date">Break</td>
                            </tr>
                            <tr>
                                <td>
                                    <p>14:40 ~ 15:25</p>
                                </td>
                                <td class="important-date">
                                    <div>
                                        <p class="prog-title">Paper Session 2 (7 papers): Usability issues, Design Strategies, Frameworks and Toolkits</p>
                                        <p class="text-muted">Session Chair: Dilrukshi Gamage</p>
                                    </div>
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <p>15:25 ~ 15:50</p>
                                </td>
                                <td class="important-date">Break</td>
                            </tr>
                            <tr>
                                <td>
                                    <p>14:40 ~ 15:25</p>
                                </td>
                                <td class="important-date">
                                    <div>
                                        <p class="prog-title">Showcase: Asia at CHI</p>
                                        <p class="text-muted">Session Chair: Chatchavan Wacharamanotham</p>
                                    </div>
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <p>16:10 ~ 16:15</p>
                                </td>
                                <td class="important-date">Break</td>
                            </tr>
                            <tr>
                                <td>
                                    <p>16:15 ~ 17:00</p>
                                </td>
                                <td class="important-date">
                                    <div>
                                        <p class="prog-title">Paper Session 3 (7 papers): Assessing and scaffolding online learning, Behaviour change for well-being</p>
                                        <p class="text-muted">Session Chair: Yohannes Kurniawan</p>
                                    </div>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </div>
				<div id="line-separator"></div>
                <div id="programs-time" class="programs-time">
                    <h2 id="day-2">Day 2 - May 8, 2021</h2>
                    <p>The programs will be done according to Japan time <a class="timezone-link" href="https://24timezones.com/time-zone/gmt+9#gref">(GMT + 09).</a></p>
                    <table class="programs-time">
                        <tbody>
                            <tr>
                                <th style="width:30%">Time (JST)</th>
                                <th style="width:70%">Program</th>
                            </tr>
                            <tr>
                                <td>
                                    <p>13:00 ~ 13:05</p>
                                </td>
                                <td class="important-date">
                                    <div>
                                        <p class="prog-title">Opening</p>
                                        <p class="text-muted">Masitah Ghazali, General Chairs (TBC)</p>
                                    </div>
                                    </td>
                            </tr>
                            <tr>
                                <td>
                                    <p>13:05 ~ 13:40</p>
                                </td>
                                <td class="important-date">
                                    <div>
                                        <p class="prog-title">Keynote 1 - Hiromi Nakamura, University of Tokyo | <a href="#hiromi-nakamura">Bio & Abstract</a></p>
                                        <p class="text-muted">Session Chair: Manjiri Joshi</p>
                                    </div>
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <p>13:40 ~ 13:45</p>
                                </td>
                                <td class="important-date">Break</td>
                            </tr>
                            <tr>
                                <td>
                                    <p>13:45 ~ 14:30</p>
                                </td>
                                <!-- <td class="important-date">Paper session 1 (7 pax)</td> -->
                                <td class="important-date">
                                    <div>
                                        <p class="prog-title">Paper Session 4 (7 papers): Design Methods, Guidelines and Smart interfaces </a></p>
                                        <p class="text-muted">Session Chair: Naincie Pindeh</p>
                                    </div>
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <p>14:30 ~ 14:35</p>
                                </td>
                                <td class="important-date">Break</td>
                            </tr>
                            <tr>
                                <td>
                                    <p>14:35 ~ 15:20</p>
                                </td>
                                <td class="important-date">
                                    <div>
                                        <p class="prog-title">Paper Session 5 (6 papers): Designing for Inclusivity, Health and Well-being, Immersive experience</p>
                                        <p class="text-muted">Session Chair: Dhriti Dhaundiyal</p>
                                    </div>
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <p>15:20 ~ 15:25</p>
                                </td>
                                <td class="important-date">Break</td>
                            </tr>
                            <tr>
                                <td>
                                    <p>15:25 ~ 16:35</p>
                                </td>
                                <td class="important-date">
                                    <div>
                                        <p class="prog-title">Posters (14 Posters)</p>
                                        <p class="text-muted">Session Chair: Ganesh Bhutkar</p>
                                    </div>
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <p>16:35 ~ 16:40</p>
                                </td>
                                <td class="important-date">Break</td>
                            </tr>
                            <tr>
                                <td>
                                    <p>16:40 ~ 16:50</p>
                                </td>
                                <td class="important-date">
                                    <div>
                                        <p class="prog-title">Recognition and Closing Remarks</p>
                                        <p class="text-muted">Speaker: Briane Samson, General Chair</p>
                                    </div>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <div id="line-separator"></div>
                    <div>
                        <h2 id="keynote-speakers">Keynote Speakers</h2>
                        <h3><b>Day 1 Keynote </b></h3>
                        <div id="separator"></div>
                        <div id="gierad_laput" class="keynote-desc">
                            <img width="275px" height="275px"class="keynote-img" alt="keynote-1" src="images/gierad_laput.jpg">
                            <div class="keynote-bio">
                                <h4><a href="https://www.gierad.com/">Gierad Laput, Apple</b></a></h4>
                                <p>Gierad Laput is a Research and Engineering Manager at Apple, where he leads the Sensing Technologies Group under Machine Learning and AI. At Apple, they imagine and build technologies that make a profound impact on millions of people through research and development in sensing and AI. Their work has now been applied in health technologies, context-driven systems, and natural + assistive interactions.

                                    He completed his Ph.D. and M.S. in Human-Computer Interaction at Carnegie Mellon University, and a B.S. in Electrical Engineering at the University of Michigan. Prior to Apple, he was a Google Ph.D. Fellow, a recipient of the Fast Company Innovation by Design Award, a Disney Imagineer, and a recipient of eight Best Paper Awards and Nominations at premier venues in human-computer interaction. He is also an Affiliate Faculty at Carnegie Mellon University's School of Computer Science.</p>
                            </div>
                        </div>
                        <div id="separator"></div>
                        <h5>Abstract</h5>
                        <div class="keynote-abstract">
                            <p><b>Context-Driven Implicit Interactions</b></p>
                            <p>As computing proliferates into everyday life, systems that understand people’s context of use are of paramount importance. Regardless of whether the platform is a mobile device, a wearable, or embedded in the environment, context offers an implicit dimension that will become highly important if we are to power more human-centric experiences. In this talk, I discuss the construction and evaluation of sensing technologies that can be practically deployed and yet still greatly enhance contextual awareness, primarily drawing upon machine learning to unlock a wide range of applications. I'll discuss some of my team's recent work at Apple, and I conclude with a vision of how rich contextual awareness can enable more powerful experiences across broader domains.</p>
                        </div>

                        <div id="separator"></div>
                        <h3><b>Day 2 Keynote </b></h3>
                        <div id="hiromi-nakamura" class="keynote-desc">
                            <img width="275px" height="275px"class="keynote-img" alt="keynote-1" src="images/hiromi_nakamura.png">
                            <div class="keynote-bio">
                                <h4><b>Hiromi Nakamura, University of Tokyo</b></h4>
                                <p>Hiromi Nakamura received her Ph.D. degree in Engineering from Meiji University in 2014. From 2014 to 2017, she was a post-doctoral researcher (research fellowship for young scientists (JSPS-PD)) with the University of Tokyo, and from 2017 to 2019 with National Institute of Advanced Industrial Science and Technology. From 2019 to 2020, she was a Project Research Associate with the University of Tokyo. Since 2020, she has been a Project Associate Professor with the University of Tokyo. Her research interests include virtual reality, human computer interaction, and augmented human.</p>
                            </div>
                        </div>
                        <div id="separator"></div>
                        <h5>Abstract</h5>
                        <div class="keynote-abstract">
                            <p><b>Augmenting abilities, body, and taste</b></p>
                            <p>Applying electrical stimulation to humans can control various sensations and movements. In this talk, we will introduce our research and case studies on the control and augmentation of taste by electrical stimulation. I will also introduce the human augmentation project conducted by Rekimoto Lab, where I am currently affiliated.</p>
                        </div>
                    </div>

                    <div id="line-separator"></div>
                    <div>
                        <h2 id="paper-sessions">Paper Sessions</h2>
                        <h4>Day 1, Paper Session 1</h4>
                        <table class="programs-time">
                            <tbody>
                                <tr>
                                    <th style="width:30%">Time (JST)</th>
                                    <th style="width:70%">Paper Title and Abstract</th>
                                </tr>
                                <tr>
                                    <td>
                                        <p>13:50 ~ 13:56</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">FacialPen: Using Facial Detection to Augment Pen-Based Interaction</p>
                                            <p class="text-muted">Xinrui Fang, Chengshuo Xia, Yuta Sugiura</p>
                                            <p class="paper-desc">Pen-based interactions have been ubiquitously adopted on mobile and stationary devices, but the usability can be further augmented through the use of advanced techniques. In this work, we propose FacialPen, a prototype that uses facial gestures to trigger commands for pen-based manipulation. In our prototype, a fisheye camera is mounted to the end of a stylus that provides a broad view from which to capture the human face. We facilitated an elicitation study to identify natural and user-defined gestures for interactions with facial expressions. Different gestures can be further discerned via face detection and a classification pipeline. We designed a sketching demonstration application to explore usage scenarios and evaluated the effectiveness of FacialPen through a qualitative study. The user study posits that FacialPen supports efficiency by reducing screen widgets, enabling the continuity of creation work and liberating the user’s stylus holding postures when switching sketch functions.</p>
                                        </div>
                                        </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>13:56 ~ 14:02</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Hover-Based Reachability Technique for Executing Single-Touch Gesture on Smartphone</p>
                                            <p class="text-muted">Ryo Ikeda, Kyohei Hakka, Buntarou Shizuki</p>
                                            <p class="paper-desc">There are unreachable areas with the thumb when users operate a smartphone with only one hand. Many reachability techniques have been developed to allow users to operate in unreachable areas. However, many of these techniques are designed to perform only a tap gesture and cannot perform other single-touch gestures such as long-tap, double-tap, swipe, and drag. To enable users to perform all single-touch gestures on the unreachable area, we designed a hover-based reachability technique using a cursor. Moreover, we conducted a pilot study to investigate the \emphasis{user performance with our technique} compared to the existing techniques which are One-Handed Mode (OM) and Event Forward Cursor (EC). The result showed that compared to EC, which is the cursor technique same as ours, our technique was faster except for double-tap when the target was small. On the other hand, our technique was slower than OM, which is the technique that shrinks the entire screen. We also discussed the improvement of our technique based on the results.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>14:02 ~ 14:08</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Word-Copying on a Website as a Word Complexity Indicator and the Relation to Web Users' Preferred Languages</p>
                                            <p class="text-muted">Ilan Kirsh</p>
                                            <p class="paper-desc">The first step toward accessibility improvement in the context of Human-Computer Interaction (HCI) is the identification of potential barriers. A recent study shows that words that are frequently copied to the clipboard by web users are relatively complex. A plausible reason is that users copy challenging words to search for a translation or more information. Accordingly, tracking word-copying operations of web users may be useful to identify complex words. This study focuses on the users that apply word-copying. It shows significant differences in the frequency of word-copying operations among different populations of users. On the examined website, whose content is in English, users whose preferred language is not English copied single words to the clipboard significantly more frequently than users whose preferred language is English. Further analysis of the data also shows that word-copying was more frequent among users whose preferred languages have low proximity to English, such as Asian languages, compared to Western European languages. These results support the observation that word-copying indicates complexity, as it is reasonable to expect that native speakers of foreign languages (and especially of languages that are considerably different from the website's language) are more likely to need help with complex words. Word complexity is subjective and audience-dependent. This study contributes to the understanding of which users tend to use word-copying, and accordingly, in which context word-copying data can be used as a word complexity indicator. It also introduces a new practical approach for detecting language barriers in order to improve language accessibility on global websites.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>14:08 ~ 14:14</p>
                                    </td>
                                    <!-- <td class="important-date">Paper session 1 (7 pax)</td> -->
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">HyperButton: In-video Question Answering via Interactive Buttons and Hyperlinks</p>
                                            <p class="text-muted">Jeongyeon Kim, Junyong Park, I-Hao Lu</p>
                                            <p class="paper-desc">Despite the advantages of video-based learning content, the video involves learners as passive viewers instead of active participants. We first conducted formative interviews with 12 participants to investigate natural user behaviors when learners have questions while watching online video lectures, and the result reveals that learners usually use web search to find answers for questions. Based on the formative interview results, we designed and developed HyperButton, an interactive video interface that supports collaborative question answering via in-video buttons and hyperlinks. In the user study, we find that HyperButton significantly improves the usability of the video interface. We further discuss design implications for an interactive video interface augmented with learner-generated material at scale.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>14:14 ~ 14:20</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Personal Identification using Gait Data on Slipper-device with Accelerometer</p>
                                            <p class="text-muted">Miyu Fujii, Kaho Kato, Chengshuo Xia, Yuta Sugiura</p>
                                            <p class="paper-desc">In this paper we presented a method of gait identification by slippers with an accelerometer to perform privacy-friendly personal identification. The gait data from accelerometer during walking is adopted from developed slipper devices as the personal unique data used for identification. Gait data is processed by Fast Fourier Transform to extract the frequency features and the Support vector machine (SVM) is used to identify the subject. Through assessing the different segmentation window size and various sensor positions, the results showed that an average accuracy was 95.0 % using six sensors, and an average accuracy of 93.3 % using three sensors placed at optimal positions.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>14:20 ~ 14:26</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">A User-based Mid-air Hand Gesture Set for Spreadsheets</p>
                                            <p class="text-muted">Yuta Takayama, Yuu Ichikawa, Buntarou Shizuki, Ikkaku Kawaguchi, Shin Takahashi</p>
                                            <p class="paper-desc">The spreadsheet is one of the most popular general user interfaces. Table manipulation, such as cell insertion and removal, is usually performed by selecting a menu command or using shortcut keys. However, the enormous number of shortcut keys makes them difficult to learn and remember. We sought to design a mid-air hand gesture-based interface for table manipulation in spreadsheet applications. As hand gestures and table manipulations are both spatial in nature, there should be a natural mapping between them. In this paper, we performed two user studies to derive a user-defined gesture set allowing 13 types of table manipulation. In the first study, we collected mid-air hand gestures devised by participants for manipulations implemented in existing spreadsheet software. In the second study, we asked other participants to vote for their most preferred gestures. We analyzed the characteristics of the collected gestures and votes, and created a final user-defined gesture set.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>14:26 ~ 14:32</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Apple Swipe: A Mobile Game Apps for Visually Impaired Users Using Binaural Sounds</p>
                                            <p class="text-muted">Noris Mohd Norowi, Habibunnajar Azman, Nor Wahiza Abdul Wahat</p>
                                            <p class="paper-desc">This paper describes the development of a mobile game application for a visually impaired users using bidirectional sounds. This basic game is based loosely on the Fruit Ninja game where users need to slash the fruits to score by using the swipe gesture on the mobile phone’s touch screen. The significance of this development is based on the simple interface to minimize latency due to heavy graphics computation and to utilize the the audio cues so that it will be suitable to be played by users with visual impairments. System Development Life Cycle which is SDLC have been implemented based on the main five phases. Standard System Development Life Cycle (SDLC) was implemented, including the analysis, design, development, testing and evaluation phases to ensure that the game suits the requirement of the targeted users. The project was conducted in three phases - Preliminary Test, Pilot Test and Final Test. 90% among the users of mixed ability were able to play this game and interacted through gestures such as touching and swiping screen of the mobile device. 75% of the users demonstrated that they could play game without depending on visual cues, i.e. only depending on bidirectional sounds (audio cues). It is hoped that this project can be a reference point for the development of mobile apps games for visually impaired users.</p>
                                        </div>
                                    </td>
                                </tr>
                            </tbody>
                        </table>
                        <div id="separator"></div>
                        <h4>Day 1, Paper Session 2 </h4>
                        <table class="programs-time">
                            <tbody>
                                <tr>
                                    <th style="width:30%">Time (JST)</th>
                                    <th style="width:70%">Paper Title and Abstract</th>
                                </tr>
                                <tr>
                                    <td>
                                        <p>14:40 ~ 14:46</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">“I Didn’t Know Until I Saw Siri on Reels”: Studying Gen Z Users’ Voice Assistant Navigation</p>
                                            <p class="text-muted">Aayushi Bharadwaj, Ambika R Menon, Pranjal Jain</p>
                                            <p class="paper-desc">Gen Z users have the highest penetration rate for adopting voice technology, but statistically, they engage less with voice technology. Our findings from the evaluation of Google Assistant and Siri usage reveal that reduced engagement is due to lack of information retention. Broken interaction while performing tasks, communication breakdowns, lack of prompts for extended learnability, and limited design scope that focuses mainly on usability and conversation design hinders user navigation. This paper analyzes empirical data on how users interact with smartphones’ voice assistants through a survey (n=74), interviews, and participatory design activities (n=8). While Voice Assistant studies focus on children, adults, and low literate users, we extend the analysis from the Gen Z perspective. Finally, we articulate design insights that shape existing usability challenges and further explore the scope for auditory and visual design.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>14:46 ~ 14:52</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Running or Jogging Together towards the Future, Virtually</p>
                                            <p class="text-muted">Chen Woon Choong, Noris Mohd Norowi, Shyamala C Doraisamy, Mas Rina Mustaffa</p>
                                            <p class="paper-desc">Running or jogging is one of the physical exercises that is capable of improving one’s healthy lifestyle apart from enhancing social interaction such as running or jogging in group of friends. To run or jog with friends could be fun, enjoyable, and encouraging but to run or jog with compatible friends having the same pace, endurance, capability, same time, same day, and same venue are not easy. At the present moment, there are various types of running applications available that allows running or jogging to be executed; 1) either physically or virtually; 2) either in a collocated or different locations; 3) either individually or group; 4) either competitive, charity, or training; or 5) run or jog for health purposes. However, these applications either have to pay to use its comprehensive functions or have restricted functions to use if available for free. Therefore, a virtual running application is being proposed that allows runners or joggers to use allowing them to; 1) run or jog individually or group; 2) create their own running or jogging events; 3) avatars to show running or jogging positions in group activity; 4) elevation gains; and 5) allowing split run or jog, split venues, split times, and split distances to be displayed. Comparing previous studies to improve what the proposed virtual system are lacking in order to produce Human Computer Interfaces that are friendly, ease of use, satisfying, and enhancing social interaction. The improved features enable initiators to create running events and all running events’ status to be displayed within the proposed system. It has avatars feature to reflect runners’ current position, have running venues display, and no uploading results to organizer required.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>14:42 ~ 14:58</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Exploring How to Display Referential Action to Support Remote Group Discussion</p>
                                            <p class="text-muted">Tzu-Yang Wang, Yuki Noaki, Hideaki Kuzuoka</p>
                                            <p class="paper-desc">Nowadays, remote conferences are widely seen in many situations. Although there is little problem to conduct one-on-one remote conferences, remote group discussion still contains many challenges. One of the main issue is that the remote participants often unnotice the referential action performed by the local participants. To solve such problem, we proposed to develop a function that automatically detects the presence of referential action and displays to the remote participant. One of the issues for this function is about what kind of information of the referential action should be provided and how the information should be displayed. In this research, we conducted a lab study to compare two displaying methods: Picture-in-Picture (PiP) and auto-pilot and compare two displaying contents: object being referred and person performing the referential action. The result shows that the PiP method had higher usability and remote participant had higher opportunity to join the conversation with the PiP method. On the other hand, displaying object being referred had higher usability.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>14:58 ~ 15:04</p>
                                    </td>
                                    <!-- <td class="important-date">Paper session 1 (7 pax)</td> -->
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Social Affordances of Digital Technologies: A Tentative Framework for HCI Research</p>
                                            <p class="text-muted">Raja Jamilah Raja Yusof, Victor Kaptelinin</p>
                                            <p class="paper-desc">The concept of “social affordances” is commonly used in HCI research. However, the advantages and limitations associated with employing the concept are yet to be fully understood. This paper presents a critical examination of “social affordances”, which includes a discussion of current uses of the concept in HCI and a comparison of “social affordances” with more traditional interpretations of “affordances”. We argue that making full use of “social affordances” as an analytical tool in HCI requires an unpacking of the relationship between perceiving a potential action, supported by the environment, and utilizing the potential and actually carrying out the action. We also argue that in case of “social affordances” it is particularly apparent that the perception of an affordance does not automatically result in a problem-free execution of the respective action, and needs to be integrated with other processes within the overall structure of action regulation. We propose a tentative framework for the analysis of the interplay between perception and action in the enactment of social affordances. Implications of the framework for employing the concept of social affordances in HCI research are discussed.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>15:04 ~ 15:08</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Mobile Usage in the Organisational Context</p>
                                            <p class="text-muted">Shweta Roy Chowdhury, Malika Mantri</p>
                                            <p class="paper-desc">"The number of smartphone users worldwide today surpasses 3 billion and is forecasted to further grow by several hundred million in the next few years. According to Statista, China, India and the United States are the countries with the highest number of smartphone users, with each country easily surpassing the 100 million mark. That means most people are using their phones to do a range of activities every day. We are doing everything from ordering food to finding jobs to even consulting doctors on the mobile phone today. The average time a user spends on their mobile phone has gone up to almost 4 hours per day. It is an omnipresent device and it is not just the millennials who are hooked to their mobile phones. The older generations are also spending a significant amount of time on their mobile phones. Mobile–first approach, has thus become a great strategy to employ for digital products.

                                                However, the mobile usage in the organisational context is still on the fringes and not a mainstream behaviour yet. There are various reasons why employees are still not using their mobile as a preferred device in the workplace. The reasons range from device capabilities like storage, screen real-estate to contextual factors like laptop already being a preferred device for heavy software that they may be using for work. A global research was initiated by by a technology organisation that develops Human Capital Management (HCM) Software in a bid to understand the factors influencing mobile usage in the workplace better. The objective of this global study was to uncover insights, trends and themes that could potentially inform mobile product development across pillars for this software company. End user data was collected and analysed in order to understand the factors that impact the current mobile experience and also identify insights that can help craft the future mobile experience for this HCM product. The study captures the mobile mental model of the end user and also uncovers moments of friction in the current experience through user journey mapping. It introduces the 3E Model of Mobile Experience- Explore, Enable & Engage. The study also distils the insights into an application-based toolkit called the Mobile Innovation Toolkit that puts together a set of triggers to enable innovation in the mobile product development process."</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>15:08 ~ 15:14</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Designing a chatbot for survivors of sexual violence: exploratory study for hybrid approach combining rule-based chatbot and ML-based chatbot</p>
                                            <p class="text-muted">Wookjae Maeng, Joonhwan Lee</p>
                                            <p class="paper-desc">Chatbots are developed using two approaches: rule-based and ML-based. The former has a scripted tree structure consisting of questions and answers, while the latter can understand the intent of a user's question and generate answers from machine learning. Despite these benefits, each method has drawbacks: rule-based chatbots cannot answer slightly different questions that have the same meaning in the patterns, and ML-based chatbots have difficulty performing continuous conversations while keeping the conversation context. We propose the concept of a hybrid chatbot that combines a rule-based chatbot and an ML-based chatbot to overcome the limitations of each. We conducted an exploratory study to investigate how a hybrid chatbot could support a survivor of sexual violence. A total of 349 questions asked from the stance of survivors were collected and analyzed. We found that the most frequently asked questions were about the punishment for sexual violence, the police report, and the list of support centers. Also, 30% of the questions omitted contextual information about sexual violence, and 10% of questions consisted of only keywords, not complete sentences. We suggest two design implications for the hybrid chatbot based on the survey's findings: 1) dialog flow for helping survivors understand the abuse experience sufficiently to report the sexual violence to police, and 2) contextualization strategies for connecting dialog flow with questions from the survivors.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>15:14 ~ 15:20</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Improving The Usability of Personal Health Record in Mobile Health Application for People with Autoimmune Disease</p>
                                            <p class="text-muted">Yasmin Salamah, Rahma Dany Asyifa, Auzi Asfarian</p>
                                            <p class="paper-desc">Personal Health Record (PHR) is a technology that usually is targeted to people with chronic illness or in the elderly and designed to supplement medical care with health monitoring outside traditional care environments in hospitals such as in person-visits through a mobile application. The widespread adoption and use of PHRs will not occur unless it provides good usability for users. Autoimmune is a condition where an immune system response attacks its host. There are 80+ types of autoimmune diseases. Some autoimmune diseases are life-threatening, and most are debilitating and require a lifetime of treatment. The variability in the development of daily symptoms and the condition of the patients with an autoimmune disease increases the need for PHR. Thymun is a mobile application made for people with autoimmune diseases and contains PHR as its main feature. In this study, we do a usability evaluation in the previous iteration and also gather the needs and problems that patients have with their traditional way of monitoring their health. After the founded usability problems and newfound needs, we then redesign the product in the 2nd iteration and then conduct a usability evaluation. It was found that the feature with the smallest usability score is symptoms recording. The results of the interview after the test obtained qualitative information about the problems experienced by participants when undergoing the test and the participants' perceptions as users of the application design when using the prototype. Finally, a post-test survey was carried out using the SUS test instrument, which obtained a usability score of 74. The 2nd iteration has a better satisfaction rate, mission usability score, and more positive remarks.</p>
                                        </div>
                                    </td>
                                </tr>
                            </tbody>
                            <div id="separator"></div>
                        <h4>Day 1, Paper Session 3 </h4>
                        <table class="programs-time">
                            <tbody>
                                <tr>
                                    <th style="width:30%">Time (JST)</th>
                                    <th style="width:70%">Paper Title and Abstract</th>
                                </tr>
                                <tr>
                                    <td>
                                        <p>16:15 ~ 16:21</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Are Learners Satisfied with MOOC Experience? Assessing and Improving Online Learners’ Interactions</p>
                                            <p class="text-muted">Jiaqi Wang, Hua Shen, Chacha Chen, Frank Ritter</p>
                                            <p class="paper-desc">With the prevalence of the COVID-19 pandemic, most students study remotely online, which fully unleashes the benefits of massive open online course (MOOC) platforms. MOOC platforms offer various advantages over traditional education, such as no geographic constraints, no time restrictions, easy accessibility, and lower costs to access in several ways. Still, it is inevitable that there still remain significant challenges that hamper the development and popularity of MOOCs. Interactions and collaborated learning remain as vital weaknesses. In this paper, we are interested in improving MOOC interactions by investigating learners’ experience with current popular MOOC platforms with a survey. We conduct a task analysis on three popular MOOC platforms, Coursera, LinkedIn Learning, and Canvas, to analyze whether and how they include key interaction functions. In addition, we conduct a case study to better understand the drawbacks of current user experiences. We found that learner-instructor and teamwork interaction affect users' experience most. Based on our findings, we propose a set of comprehensive guidelines, called IN-MOOC, to facilitate interpersonal interactions on MOOC platforms. In summary, IN-MOOC provides comprehensive and hierarchical guidelines to improve users' experience via enhancing interpersonal interaction on MOOC platforms.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>16:21 ~ 16:27</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Scaffolding Social Presence in MOOCs</p>
                                            <p class="text-muted">Dilrukshi Gamage</p>
                                            <p class="paper-desc">Massive Open Online Courses (MOOCs) often lack valuable social presence within courses thought we know it contributes to highergains in learning experience. MOOCs platforms do provide forums, however these often scaffold cognitive presence in the interactions,as opposed to social presence. Unlike in small, closed learning environments, MOOCs face challenges of scale, and social diversitywhen trying to support social presence. In this research, we present a conceptual framework of 4 phases: Cluster, Orient, Focusand Network to scaffold better social interaction in MOOCs. The framework leverages clustered groups with a community leaderfacilitating the conversations leading social presence. It also enables scaling social presence in MOOC forums to resemble a smallcommunity. We present preliminary results of a field deployment of the framework with a MOOC of27,554students. We show thatthis framework scaffolds social presence through epistemic network analysis and that it has potential to do so at scale</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>16:27 ~ 16:33</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Investigating the Acceptability and Perceived Effectiveness of a Chatbot in Helping Students Assess their Well-being</p>
                                            <p class="text-muted">Ethel Ong, Dominic Ethan Sia, Marco Jalen Yu, Jaycee Montenegro, Justine Leo Daliva</p>
                                            <p class="paper-desc">Students are vulnerable to health problems due to numerous stressors and overwhelming pressure at home and in school. With the rapid development in AI technologies, there are many opportunities to develop tools that can assist students affected by these problems. Chatbots can serve as a platform for individuals to share their emotions, gain motivation to maintain a healthy lifestyle, and consider professional help. In this paper, we describe the design of our chatbot, named Abot, to encourage students to improve their lifestyle habits and well-being, which are important components to maintaining an optimal mental health. Validation with 25 senior high school students who used Abot for a one-week period showed a positive improvement in their physical well-being, positive change in their social well-being, and positive change in their academic well-being. Students' evaluation of Abot on a 4-point Likert scale showed an average score of 3.35 on performance, 3.36 on humanity, and 3.68 on affect, which points to perceived user acceptability of the chatbot as a potential tool to help them manage their health and well-being.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>16:33 ~ 16:39</p>
                                    </td>
                                    <!-- <td class="important-date">Paper session 1 (7 pax)</td> -->
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Changing Computer-Usage Behaviors: What Users Want, Use, and Experience</p>
                                            <p class="text-muted">Mina Khan, Kathryn Wantlin, Zeel Patel, Elena Glassman, Pattie Maes</p>
                                            <p class="paper-desc">Computer-related behavior change is helpful for well-being. We conducted a survey to investigate three research questions and further inform the design of computer-related behavior change applications. RQ1: What do people want to change and why/how? RQ2: What applications do people use or have used, why do they work or not, and what additional support is desired? RQ3: What are helpful/unhelpful computer breaks and why? Our survey had 68 participants and three key findings. First, time management is a primary concern, but emotional and physical side-effects are also important. Second, site blockers, self-trackers, and timers are commonly used, but they are ineffective as they are easy-to-ignore and not personalized. Third, away-from-computer breaks, especially involving physical activity, are helpful, whereas on-screen breaks are unhelpful, especially when they are long, because they are not refreshing. We recommend personalized and closed-loop computer-usage behavior change support and especially encouraging off-the-computer computer breaks.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>16:39 ~ 16:45</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Tracking Diverse Feelings and Activities Encourages Self-guided Holistic Behavior Change</p>
                                            <p class="text-muted">Mina Khan, Pattie Maes</p>
                                            <p class="paper-desc">Cognitive Behavioral Therapy highlights that people's thoughts, feelings, and behaviors are interconnected. Self-tracking, however, has mostly focused on a few emotions or activities. We created a mobile/web application to enable the users to track a broad range of daily activities and feelings in unison. In our 3-week study with 15 participants, the application improved the participants' self-awareness of their activities, feeling, and the correlation between their activities and feelings. Better self-awareness inspired personalized, self-guided, and holistic behavior change as the participants improved their self-care, daily planning and focus, and emotion regulation. Finally, the participants also developed a healthy and organized habit of self-reflection and even reflected on their holistic well-being and the meaning of having a `good day'. Behavior change is usually treated as an external and isolated process but our research shows that tracking a broad range of activities and feelings can inspire self-guided holistic behavior change.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>16:45 ~ 16:51</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Identifying High and Low Academic Result Holders Through Smartphone Usage Data</p>
                                            <p class="text-muted">Md. Sabbir Ahmed, Rahat Jahangir Rony, Nova Ahmed</p>
                                            <p class="paper-desc">Nowadays, smartphones have become an inseparable part of student life. Many previous studies have explored smartphone usage behavior in different contexts. However, to our best knowledge, smartphone usage behavior of the high and low academic result holders is still very less studied. Thus, in the context of Bangladesh, using 7 days’ actual smartphone usage data of high [N=32] and low [N=44] performers, we investigate the smartphone usage of these two groups. Our findings show that low performers are more focused on certain apps of the Launcher category whereas high performers are more focused on certain apps of the Video category. Moreover, we find that low performers micro usage and review session number is statistically significantly (p<0.05) higher. Based on different smartphone usage data, we build a machine learning model which classifies these two groups of students with 73.33% accuracy. Thus, findings of our study suggests that high and low performers can be identified through smartphone usage data.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>16:51 ~ 16:57</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Together we learn better: leveraging communities of practise for MOOC learners</p>
                                            <p class="text-muted">Dilrukshi Gamage, Mark E Whiting</p>
                                            <p class="paper-desc">Participants in MOOCs often feel isolated and disconnected from peer interactions. Navigating meaningful peer interactions, a sense of belonging, and social presence is difficult in MOOC platforms. MOOC users often rely on social media for such connections and learner interactions. However, navigating the social media feed, maintaining the attention of a community is often challenged in such platforms. We present PeerCollab, a web-based platform that provides affordance to create communities and support meaningful peer interactions with a closed-knit group of learners. Early stages of the platform was evaluated using a control study with 22 participants and a field study with 56 participants over 6 weeks.The result indicates insights on how learners build a sense of belonging and develop peer interactions leading to close-knit learning circles. Our goal is to provide more meaningful interactions and create a community to bring a culture of social learning to the decentralized, isolated MOOC learners.</p>
                                        </div>
                                    </td>
                                </tr>
                            </tbody>
                        </table>
                        <h2 id="showcase">Showcase</h2>
                        <h4>Day 1, Showcase</h4>
                        <table class="programs-time">
                            <tbody>
                                <tr>
                                    <th style="width:30%">Time (JST)</th>
                                    <th style="width:70%">Showcase Title and Abstract</th>
                                </tr>
                                <tr>
                                    <td>
                                        <p>15:30 ~ 15:34</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">You Recommend, I Buy: How and Why People Engage in Instant Messaging Based Social Commerce</p>
                                            <p class="text-muted">Hancheng Cao, Zhilong Chen, Mengjie Cheng, Shuling Zhao, Tao Wang, Yong Li</p>
                                            <p class="paper-desc">As an emerging business phenomenon especially in China, instant messaging (IM) based social commerce is growing increasingly popular, attracting hundreds of millions of users and is becoming one important way where people make everyday purchases. Such platforms embed shopping experiences within IM apps, e.g., WeChat, WhatsApp, where real-world friends post and recommend products from the platforms in IM group chats and quite often form lasting recommending/buying relationships. How and why do users engage in IM based social commerce? Do such platforms create novel experiences that are distinct from prior commerce? And do these platforms bring changes to user social lives and relationships? To shed light on these questions, we launched a qualitative study where we carried out semi-structured interviews on 12 instant messaging based social commerce users in China. We showed that IM based social commerce: 1) enables more reachable, cost-reducing, and immersive user shopping experience, 2) shapes user decision-making process in shopping through pre-existing social relationship, mutual trust, shared identity, and community norm, and 3) creates novel social interactions, which can contribute to new tie formation while maintaining existing social relationships. We demonstrate that all these unique aspects link closely to the characteristics of IM platforms, as well as the coupling of user social and economic lives under such business model. Our study provides important research and design implications for social commerce, and decentralized, trusted socio-technical systems in general. (accepted to CSCW 2021)</p>
                                        </div>
                                        </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>15:34 ~ 15:38</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">More Kawaii than a Real-Person Live Streamer: Understanding How the Otaku Community Engages with and Perceives Virtual YouTubers</p>
                                            <p class="text-muted">Zhicong Lu, Chenxinran Shen, Jiannan Li, Hong Shen, Daniel Wigdor</p>
                                            <p class="paper-desc">Live streaming has become increasingly popular, with most streamers presenting their real-life appearance. However, Virtual YouTubers (VTubers), virtual 2D or 3D avatars that are voiced by humans, are emerging as live streamers and attracting a growing viewership in East Asia. Although prior research has found that many viewers seek real-life interpersonal interactions with real-person streamers, it is currently unknown what makes VTuber live streams engaging or how they are perceived differently than real-person streamers. We conducted an interview study to understand how viewers engage with VTubers and perceive the identities of the voice actors behind the avatars (i.e., Nakanohito). The data revealed that Virtual avatars bring unique performative opportunities which result in different viewer expectations and interpretations of VTuber behavior. Viewers intentionally upheld the disembodiment of VTuber avatars from their voice actors. We uncover the nuances in viewer perceptions and attitudes and further discuss the implications of VTuber practices to the understanding of live streaming in general.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>15:38 ~ 15:42</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">TiltChair: Manipulative Posture Guidance by Actively Inclining the Seat of an Office Chair</p>
                                            <p class="text-muted">Kazuyuki Fujita, Aoi Suzuki, Kazuki Takashima, Kaori Ikematsu, Yoshifumi Kitamura</p>
                                            <p class="paper-desc">We propose TiltChair, an actuated office chair that physically manipulates the user's posture by actively inclining the chair's seat to address problems associated with prolonged sitting. The system controls the inclination angle and motion speed with the aim of achieving manipulative but unobtrusive posture guidance. To demonstrate its potential, we first built a prototype of TiltChair with a tiltable seat by pneumatic control. We then investigated the effects of the seat's inclination angle and motions on task performance and overall sitting experience through two experiments. The results show that the inclination angle mainly affects the difficulty of maintaining the posture, while the motion speed affected the conspicuousness and subjective acceptability of the motion. However, these seating conditions did not affect objective task performance. Based on these results, we propose a design space for arranging the seat inclination behavior in practical scenarios, using the three dimensions of angle, speed, and continuity.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>15:42 ~ 15:46</p>
                                    </td>
                                    <!-- <td class="important-date">Paper session 1 (7 pax)</td> -->
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Learning from Home: A Mixed-Methods Analysis of Live Streaming Based Remote Education Experience in Chinese Colleges during the COVID-19 Pandemic</p>
                                            <p class="text-muted">Zhilong Chen, Hancheng Cao, Yuting Deng, Xuan Gao, Jinghua Piao, Fengli Xu, Yu Zhang, Yong Li</p>
                                            <p class="paper-desc">The COVID-19 global pandemic and resulted lockdown policies have forced education in nearly every country to switch from a traditional co-located paradigm to a pure online “distance learning from home” paradigm. Lying in the center of this learning paradigm shift is the emergence and wide adoption of distance communication tools and live streaming platforms for education. Here, we present a mixed-methods study on live streaming based education experience during the COVID-19 pandemic. We focus our analysis on Chinese higher education, carried out semi-structured interviews on 30 students, and 7 instructors from diverse colleges and disciplines, meanwhile launched a large-scale survey covering 6291 students and 1160 instructors in one leading Chinese university. Our study not only reveals important design guidelines and insights to better support current remote learning experience during the pandemic, but also provides valuable implications towards constructing future collaborative education supporting systems and experience after pandemic.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>15:46 ~ 15:50</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">A Case Study of User Experience Design in a Disrupted Context: Design and Development of a Vital Signs Self-monitoring System</p>
                                            <p class="text-muted">Chang Siang Lim, Pin Sym Foong, Adrian Yeow, Gerald CH Koh</p>
                                            <p class="paper-desc">We present a case study where we developed an interface for remote vital signs self-monitoring at a large-scale isolation facility for COVID-positive patients, under disrupted conditions. These conditions were: a lack of time, lack of access to end users, changing requirements, high risk of infection and supply chain limitations. We frst describe the background of the development of the facility and the vital signs self-monitoring system. We use the 5 commonly prescribed activities of user experience design -Empathise, Defne, Ideate, Prototype and Test-to describe how our work as user experience designers was afected by these disrupted conditions. Finally, we recommend a focus on Empathy, Prototyping and Communication for user experience practitioners and educators, whose training may be needed in similarly mission-critical, time-constrained circumstances.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>15:50 ~ 15:54</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Using Boolean Satisfiability Solvers to Help Reduce Cognitive Load and Improve Decision Making when Creating Common Academic Schedules</p>
                                            <p class="text-muted">Joshua Manzano, Adrienne Francesca Soliven, Antonio Miguel Llamas, Shenn Margareth Tinsay, Briane Paul Samson, Rafael Cabredo</p>
                                            <p class="paper-desc">Manual schedule creation often involves satisfying numerous unique and conflicting constraints, which becomes more cognitively demanding when creating a common academic schedule with other individuals. Poor decision making caused by cognitive overload can result in unsuitable schedules. This study proposes the use of Boolean satisfiability (SAT) solvers in an academic scheduling system to help students balance scheduling preferences and satisfy necessary constraints. Based on the availability of courses and the scheduling preferences of users, the system automatically resolves conflicts and presents possible schedules. In a controlled experiment with 42 undergraduate students, cognitive demand was reduced by eliminating menial decisions, which significantly optimized the creation of a common schedule among peers. We found that human errors and emotional stress were diminished, and schedules created using the system were more satisfactory to participants. Finally, we present recommendations and design implications for future academic scheduling systems.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>15:54 ~ 15:58</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Therapist Vibe: Children’s Expressions of their Emotions through Storytelling with a Chatbot</p>
                                            <p class="text-muted">Kyle-Althea Santos, Ethel Ong, Ron Resurreccion</p>
                                            <p class="paper-desc">Storytelling can develop children’s emotional intelligence when they are asked to freely talk about their emotions. While parents are responsible for teaching emotional intelligence, studies in using affective technologies to help people become aware of their emotions have also been explored. In this paper, we investigate the opportunity of this technology in enabling children to recognize and express their emotions. We describe a chatbot that leverages storytelling strategies to listen to chil- dren as they share emotional events they experienced, then guides them through reflective discipline to devise the next course of action. We report the types of emotions children choose to share with the chatbot, the kinds of support that the chatbot provided, the challenges during the conversation and children’s perception of the chatbot. From our findings, we suggest design considerations for a conversation flow that anchors on storytelling to support child-agent interaction.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>15:58 ~ 16:02</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Investigating Students’ Use of a Mental Health Chatbot to Alleviate Academic Stress</p>
                                            <p class="text-muted">Johan Oswin De Nieva, Jose Andres Joaquin, Chaste Bernard Tan, Ruzel Khyvin Marc Te, Ethel Ong</p>
                                            <p class="paper-desc">The amount of academic workload in schools can cause students to experience stress and become more susceptible to mental health problems. However, because of fear of societal stigma, students may find it more difficult to approach others about the stress they experience. A chatbot can provide an alternative avenue for stu- dents to freely share the stressful situations they are experiencing. In this study, we investigated the use of Woebot as a mechanism to help senior high school students alleviate stress from academic workload. 25 participants who engaged in daily conversations with Woebot for a two-week period rated the chatbot’s likeness to a human with a mean score of 5.56 out of 8, while its ability to un- derstand the feelings of the participants and empathize with them had a mean score of 5.61. An analysis of the chat logs showed that the participants valued Woebot’s lessons and stories while they faced challenges in cases when the chatbot generated inappropriate responses. We discuss our findings and provide design suggestions that could make conversational agents like Woebot be more useful in helping the general student population cope with stress.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>16:02 ~ 16:06</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Can Playing with Toy Blocks Reflect Behavior Problems in Children?</p>
                                            <p class="text-muted">Xiyue Wang, Kazuki Takashima, Tomoaki Adachi, Yoshifumi Kitamura</p>
                                            <p class="paper-desc">Although children’s behavioral and mental problems are generally diagnosed in clinical settings, the prediction and awareness of children’s mental wellness in daily settings are getting increased attention. Toy blocks are both accessible in most children’s daily lives and provide physicality as a unique non-verbal channel to express their inner world. In this paper, we propose a toy block approach for predicting a range of behavior problems in young children (4-6 years old) measured by the Child Behavior Checklist (CBCL). We defined and classified a set of quantitative play actions from IMU-embedded toy blocks. Play data collected from 78 preschoolers revealed that specific play actions and patterns indicate total problems, internalizing problems, and aggressive behavior in children. The results align with our qualitative observations, and suggest the potential of predicting the clinical behavior problems of children based on short free-play sessions with sensor-embedded toy blocks.</p>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <p>16:06 ~ 16:10</p>
                                    </td>
                                    <td class="important-date">
                                        <div>
                                            <p class="prog-title">Religion and Women’s Intimate Health: Towards an Inclusive Approach to Healthcare</p>
                                            <p class="text-muted">Maryam Mustafa, Kimia Tuz Zaman, Tallal Ahmad, Amna Batool, Masitah Ghazali, Nova Ahmed</p>
                                            <p class="paper-desc">We present findings from a three country study exploring the intersection between female intimate health and religious beliefs. Through a qualitative study with Muslim female populations in Pakistan, Bangladesh and Malaysia, three different Muslim majority contexts,we examine the deep impact Islamic beliefs have on female intimate health and well-being. Our study investigates the perceptions, attitudes and behaviours of Muslim women to their own intimate and sexual bodies through their experiences of menarche, marriage and reproduction and menopause. The intersection of religion and female sexual bodies and health is a neglected area within HCI and we highlight how inextricably specific Islamic values are linked with women’s reproductive health in Muslim communities. We further discuss the opportunities and challenges of designing technologies for religious, non-secular beliefs and values with the aim to improve intimate health practices amongst Muslim women and to broaden the scope of health design within HCI.</p>
                                        </div>
                                    </td>
                                </tr>
                            </tbody>
                        </table>
                    </div>

                    <div id="line-separator"></div>
                        <div class="have-questions">
                            <h2>Contact Us</h2>
                            <div id="separator"></div>
                            <div id="contacts-cfp" class="contacts">
                                <div class="contact row1">
                                    <div class="contact josh">
                                        <img width="120px" height="120px" class="chair-picture" alt="general-chair-name" src="images/josh.jpg">
                                        <div class="info-container">
                                            <p style="font-style: bold"><b>Josh (Adi B. Tedjasaputra)</b></p>
                                            <p class="contact-info">Customer Experience Insight Pty Ltd</p>
                                            <p class="contact-info"><a href = "mailto:josh@cxinsight.com.au">josh@cxinsight.com.au</a></p>
                                        </div>
                                    </div>
                                    <div class="contact masitah">
                                        <img width="120px" height="120px" class="chair-picture" alt="cfp-contact" src="images/masitah.JPG">
                                        <div class="info-container">
                                            <p style="font-style: bold"><b>Masitah Ghazali</b></p>
                                            <p class="contact-info">Universiti Teknologi Malaysia</p>
                                            <p class="contact-info"><a href = "mailto:masitah@utm.my">masitah@utm.my</a></p>
                                        </div>
                                    </div>
                                </div>
                        </div>

                </div>

                <div>
            </div>
            <div></div>
        </main>

        <footer>
            <p>Follow Our Social Media</p>
            <div class="icons">
                <span id="twitter">
                    <img height="32px" width="32px" class="twitter-icon" alt="twitter-icon" src="icons/twitter-icon.svg">
                </span>
                <span id="facebook">
                    <img height="32px" width="32px" class="facebook-icon" alt="facebook-icon" src="icons/facebook-icon.svg">
                </span>
            </div>
            <small>Showcasing Asian ingenuity in addressing local challenges in Human-computer Interaction research.</small>
            <small>&copy Copyright 2020 Asian CHI Symposium 2021. Photo Credit: 2020 Office of the City of Yokohama Representative to the Americas</small>
        </footer>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
        <script src="app.js"></script>

        <!-- include jquery -->
        <script src="//code.jquery.com/jquery-1.10.1.min.js"></script>
        <script>
            $('.dropdown').keydown(function(e){
               if(e.which == 40){ // 9-tab, 40-down-arrow
                   e.preventDefault();
                   $(this).parent().find('.dropdown-content').show();
               }

               else if(e.which == 38){
                   e.preventDefault();
                   $(this).parent().find('.dropdown-content').hide();
               }
             });
        </script>
    </body>
</html>
